---
layout: page
---

<h2>APCs</h2>

<h3>Predictive Comparisons Generalize Regression Coefficients</h3>

<p>At the heart of this package is the idea of a <em>predictive comparison</em>: We vary the input of interest holding the other inputs constant, and look at the differences in predicted values. Let \(u\) represent the input of interest and \(v\) the (vector of) other inputs. Let \(f\) be a functinon making predictions, so</p>

<p>\[\hat{y} = f(u,v)\]</p>

<p>Our \(f\) could come from any predictive model. If we have a statistical model, then probably we would choose </p>

<p>\[f(u,v) = \mathcal{E}[y \mid u, v, \theta]\]</p>

<p>(where \(\theta\) are the parameters of the model). But we need not have a statistical model at all. The prediction function \(f\) could come from a random forest, or a support vector machine.</p>

<p>Given the function \(f\) and a choice of \(u_1\), \(u_2\), and \(v\), we can compute</p>

<p>\[\delta_{u_1 \rightarrow u_2, v} = \frac{f(u_2, v) - f(u_1, v)}{u_2-u_1}\]</p>

<p>If \(f\) were a linear model with no interactions, the above would not depend on the particular choices of \(u_1\), \(u_2\), and \(v\) and would be the regression coefficient corresponding to \(u\). This is the formal sense in which predictive comparisons generalize regression coefficients. Since for more complicated models this varies as the inputs vary, we will take an average across a well chosen set of inputs. </p>

<h3>Choice of Inputs</h3>

<p>The APC is</p>

<p>\[\frac{\mathcal{E}[\Delta_f]}{\mathcal{E}[\Delta_u]}\]</p>

<p>where \(\Delta_f = f(u_2,v) - f(u_1,v)\), \(\Delta_u = u_2 - u_1\), and \(\mathcal{E}\) is expectation under the following process:</p>

<ol>
<li>sample \(v\) from the (marginal) distribution of the corresponding inputs</li>
<li>sample \(u_1\) and \(u_2\) independently from the distribution of \(u\) conditional on \(v\)</li>
</ol>

<p>The reason for this definition is that we want to use values of \(v\) that are representative of our data generation process, and transitions in \(u\) that are representative of what really occurs at those values of \(v\).</p>

<p>Computing the numerator and denominator separately rather than taking an expected value of \(\delta_{u_1 \rightarrow u_2, v}\) amounts to weighting by the size of \((u_2 - u_1)\). This avoids having the result excessively influenced by small changes in \(u\).</p>

<h3>Estimation</h3>

<p>The rows of our data represent samples from the joint distribution \(u\), \(v\), so each row amounts to a sample from \(v\) followed by a sample \(u_1\) conditional on \(v\). The difficult thing is drawing another sample \(u_2\) conditional on \(v\). We approximate these by assigning weights to rows based on the proximity of the \(v\) in that row to the \(v\) in the row in question. The weights are:</p>

<p>\[\frac{1}{\text{mahalanobisConstantTerm} + \text{(mahalanobis distance)}}\]</p>

<p>The <a href="https://en.wikipedia.org/wiki/Mahalanobis_distance"><em>mahalanobis distance</em></a> is a unitless version of distance that takes into account the correlation structure of \(v\). The <em>mahalanobisConstantTerm</em> (which defaults to 1, but this is not always an appropriate choice) prevents all of the weight from going to the closest points. More work needs to be done in thinking about the weights.</p>

<p>For more details, see <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9531.2007.00181.x/abstract">Gelman and Pardoe 2007</a> (section 4), <a href="more-renormalize-weights.html">my note</a> explaining a small change from the weights described in the paper, or <a href="https://github.com/dchudz/predcomps/blob/master/R/pairs.R">my code</a> that computes the appropriate weights.</p>

<h3>Absolute Version</h3>

<p>The absolute APC (as opposed to the signed version described above) replaces \(\Delta_f = f(u_2,v) - f(u_1,v)\) above with \(|\Delta_f| = |f(u_2,v) - f(u_1,v)|\). See e.g. the input \(u_8\) in my <a href="examples-simulated-linear-model-interactions.html">simulated linear model with interactions</a> for an example where the signed APC is roughly 0 but the absolute APC is large.</p>

<p>By default, I always compute and display an absolute version of the APC alongside the signed version. </p>

<h3>A Small Example</h3>

<p>This is a example running APCs on a simulated linear model with independent inputs and no interactions. For more involved examples, see the <a href="examples-overview.html">examples</a> section.</p>

<p>The inputs (\(x_1\), \(x_2\), \(x_3\)) are independent, with</p>

<p>\[y \sim 2x_1 - 2x_2 + x_3 + \mathcal{N}(0,.1)\]</p>

<p>First we set up the data:</p>

<pre><code class="r">n &lt;- 200
x1 &lt;- runif(n = n, min = 0, max = 1)
x2 &lt;- runif(n = n, min = 0, max = 1)
x3 &lt;- runif(n = n, min = 0, max = 10)
y &lt;- 2 * x1 + (-2) * x2 + 1 * x3 + rnorm(n, sd = 0.1)
df &lt;- data.frame(x1, x2, x3, y)
</code></pre>

<p>Then we fit a linear model:</p>

<pre><code class="r">fittedLm &lt;- lm(y ~ ., data = df)
fittedLm
</code></pre>

<pre><code>## 
## Call:
## lm(formula = y ~ ., data = df)
## 
## Coefficients:
## (Intercept)           x1           x2           x3  
##      0.0127       1.9840      -1.9748       0.9975
</code></pre>

<p>We can then plot the average predictive comparisons:</p>

<pre><code class="r">library(predcomps)
apcDF &lt;- GetPredCompsDF(fittedLm, df = df)
PlotPredCompsDF(apcDF, variant = &quot;Apc&quot;) + theme_gray(base_size = 18)
</code></pre>

<pre><code>## Error: could not find function &quot;melt&quot;
</code></pre>

<p>Using different shapes / colors, both the absolute and signed versions are plotted. For symmetry, the absolute version is plotted with both a positive and negative sign. Since this is a linear model with no interactions, the signed APCs match those from the fitted linear model. </p>

<p>This is what the returned data frame <code>apcDF</code> looks like:</p>

<pre><code class="r">apcDF
</code></pre>

<pre><code>##    Input Apc.Signed Apc.Absolute Impact.Signed Impact.Absolute
## x1    x1     1.9840       1.9840        0.6734          0.6734
## x2    x2    -1.9748       1.9748       -0.6579          0.6579
## x3    x3     0.9975       0.9975        3.1822          3.1822
</code></pre>

<p>The columns plotted here are <code>Apc.Signed</code> and <code>Apc.Absolute</code>. The <a href="impact.html">next section</a> is about those columns labeled &ldquo;Impact&rdquo;.</p>


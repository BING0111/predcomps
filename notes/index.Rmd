## An R Package for Understanding Arbitrary Complex Models

As complex models become widely used, it's more important than ever to have ways of understanding them. Even when a model is built primarily for prediction (rather than primarily as an aid to understanding), we still need to know what it's telling us. If we were using linear regression with no interactions, it would be (relatively) clear how to interpret the coefficients. For more complicated models, things get difficult.

This R package is a collection of tools that are meant to generalize the idea of these coefficients to arbitrary predictive models: Holding all else equal, how does the output vary with the input of interest? The tools here apply to any model that lets you map inputs to outputs, whether it's a linear model, a GLM (with any link function), a neural network, a random forest, etc.

One advantage of the fact that these tools work equally well for any model is that they can be used to **compare models**.

### Inspiration

The ideas implemented here originate in [Gelman and Pardoe 2007](http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9531.2007.00181.x/abstract). If you are already familiar with the paper, you can [skip to the differences between that and what's here](more-compared-with-paper.html). As far as I know, this is the only implementation intended for general use.

### Installation

The package is not hosted on CRAN, but it's still easy to install:

```{r eval=FALSE}
library(devtools) # first install devtools if you haven't
install_github("predcomps", user="dchudz")
```

### Example Output

Here's an example of the output I'm calling [impact](impact.html) (which gets at a idea similar to 'variable importance' in other packages) from [an example predicting loan defaults](examples-loan-defaults.html). The model is a random forest. Note that unlike the *average predictive comparison* described in the paper, this *impact* measure is **not** per unit change in input. The units are probabilities, and hence it always makes sense to show it for all of the inputs on the same scale:

![LoanDefaultImpact](figure/LoanDefaultImpact.png)

The signed version should be interpreted as the expected value of the change in default probability for a random change in input. The absolute version is the expected absolute value, and is shown on both the positive and negative sides of horizontal axes. The signed version will always be between the two points representing the absolute version. When the signed version is close to the absolute version, the impact of a change the corresponding variable more consistently has the same sign. 

We can also look in more detail at an individual input, examining the default probability as we vary that input (holding all else equal at a few example values):

![NumTimes30To59DaysLateDefaultCurves](figure/NumTimes30To59DaysLateDefaultCurves.png)

Notice that for one particular choice of other input values, transitioning from 0 to 1 previous time 30-59 days late leads to a *decrease* in predicted default probability. See [the example](examples-loan-defaults.html) for some thoughts on why this might be.

### Current Limitations

The package has some major limitations in its current form, but we have to start somewhere:

**Input types**: At the time of this writing, all inputs to the model must be numerical (or coercable to such). In practice this means that binary or ordered categorical inputs are okay, but unordered categorical inputs are not.

**Parameters controlling the weights between pairs**: These parameters are important for reasons that are both computational and statistical, and are not yet automatically tuned for you.

## Contact

I'm very interested in feedback from folks who are trying this out. Please get in touch with me at dchudz@gmail.com.
